\section{数据处理基础}

现实世界中数据大体上都是不完整，不一致的脏数据，无法直接进行数据挖掘，或挖掘结果差强人意。为了提高数据挖掘的质量产生了数据预处理技术。 　　
数据预处理有多种方法：数据清洗，数据聚合，数据变换，数据归约等。这些数据处理技术在数据挖掘之前使用，大大提高了数据挖掘模式的质量，降低实际挖掘所需要的时间。

\subsection{原始数据集整理与统计}
首先，简要的整理一下数据集所提供的数据：

本次所提供的数据集，总共包括inf表中：

`user``age``sex``national``hometown``major``status`  

`residence``tel``health``email` 

`address``education``ability``experience`

15类数据，其主tel为主键。
\subsection{数据预处理基本方法整理}
存在不完整的（有些感兴趣的属性缺属性值，或仅包含聚集数据）、含噪声的(包含错误的或存在偏离期望的孤立点值）和不一致的（ 用于分类的编码存在差异） 数据是大型的、现实世界数据库或数据仓库的共同特点。数据预处理技术可以改进数据的质量，从而有助于提高其后的数据挖掘过程的精度和性能。由于高质量的决策必然依赖于高质量的数据，因此数据预处理是数据挖掘过程中的主要步骤。数据预处理技术主要包括：数据清理、数据集成、数据变换与数据归约。
\subsubsection{数据清洗}
其实通俗的来讲，数据清洗就是一个脏数据到”干净”数据的一个处理过程。众所周知，现实世界的数据一般是不完整的、含噪声的和不一致的。数据清理主要从填充空缺值，识别孤立点，消除噪声，并纠正数据中的不一致这几个方面来对原始数据集进行处理。

(1)空缺值的处理及其实现方式：

数据集中属性值的缺失并不少见，但是缺失的属性值并不是说其不重要，或者说其与最终的挖掘结果关联不大。缺失值也并不意味着数据就有错误。例如，一个班级在统计班级同学是否获得奖学金，因为奖学金只有少数人获得，因此，没获得者可以使这个字段为空。因此，统计数据信息的记录表格应该允许调查人使用“null”这样的无效值。此外，还有像父属性性别，子属性男或女，那么子属性其中之一避免不了会有空值。所以，在分析数据时，应当考虑对不完整个的数据进行处理。在处理时可以采用以下办法来处理空缺值。

\begin{itemize}
	\item 忽略元组；缺少类标号时通常这样处理。
	\item 忽略属性列；如果一个属性的缺失值占所有属性值的80\%以上，则可以从整个数据集中删除此属性列。
	\item 人工填写空缺值；通常情况下，此办法较为费时，只适合于数据集较小，空缺值较少的情况下。
	\item 自动填充空缺值；这个方法呢有三种策略。
\end{itemize}

策略一：使用一个全局常量填充空缺值，将空缺属性值用同一个常数替换

策略二：使用属性的均值或期望值或者众数进行默认填充。

策略三：可以通过线性回归、基于推理的工具或者决策树归纳确定空缺值的可能值来进行填充。由于使用现有数据的多数信息推测空缺值，所有有更大的机会保持属性之间的关联性。

(2)噪声数据的清理方法：

噪声数据是一个测量变量中的随机错误或偏差，其包含错误或孤立点值。导致噪声产生的原因有多种，可能是采集设备出了故障，也可能是数据录入或搜集整理的过程出现人为的失误或疏忽，或者数据传输过程中的错误等等。目前，有以下几种处理噪声数据的方法：

\ding{172}分箱；通过考察“邻居”（ 周围的值） 来平滑存储数据的值。由于分箱方法考虑相邻的值，因此是一种局部平滑方法。按照取值不同可分为：按箱平均值平滑、按箱中值平滑、按箱边界值平滑。例如：有4、6、17、32、3、9、17、65、23等9个数，分为3 箱。

箱1: 4、6、17；

箱2: 32、3、9；

箱3: 17、65、23；

接下来，我们分别按照上述几种方法对以上三箱数据进行平滑。

箱1: 9、9、9；

箱2: 3、3、3；

箱3: 17、17、17；

\ding{173}聚类；孤立点可以被聚类检测，聚类就是将类似的值组织成群或分类，直观地看落在聚类集合之外的值被视为孤立点。我们通过删除离群点来平滑数据。

\ding{174}人计算机和人工相结合；我们可以先通过已有经验对数据集中明显不符合逻辑的数据点进行处理之后，再通过回归或者数据处理算法对以初步处理后的数据集进行处理。

\ding{175}回归分析；可以通过让数据适合一个回归函数来平滑数据。如：线性回归涉及找出两个变量的最佳直线，使得一个变量可以预测另一个。多线性回归涉及多个变量，数据适合一个维面，使用回归找出适合数据的数学方程式，能够帮助消除噪声。

\subsubsection{数据集成}

数据挖掘中经常需要对数据进行聚合，将两个或多个数据源中的数据，存放近一个一致的数据存储设备中，这些数据源可能包括多个数据库、数据立方体或一般文件。

在数据集成时，有许多问题需要考虑，数据一致性和冗余是两个重要的问题。

(1)数据一致性；

(2)数据属性值冗余；

(3)元组重复问题。重复是指对于同一个数据，存在两个或多个相同的元组。

(4)数据值表现形式冲突的检测与处理。就数据集中的某一具体实体而言，如果其来自不同数据源，那么它的的属性值就有可能不同。这可能是因为数据的表示方式、缩减比例（通常用于数值属性）或数据格式编码不同。例如，重量属性可能在一个数据源中以g为单位存放，而在另一个数据源中可能kg为单位表示。

\subsubsection{数据变化}
数据变换是将数据转换成适合挖掘的形式，数据变化一般包括以下内容： 

(1)平滑。去掉数据中的噪声，这种技术包括分箱、聚类、回归。

(2)聚类。对数据进行汇总和聚集，用来为多维度数据分析构造数据立方体。例如，可以以班级为单位来统计和分析班级的成绩情况。
 
 (3)数据概化。使用概念分层，用高层次概念替换低层次“原始”数据，例如对所调查customer的地理位置信息可以将经纬度映射到较高层次的概念，如：市、州甚至国家；对ip地址，可以通过对ip分段实现泛化。
 
 数据概化，在数据的前期处理过程中很常见，其用来规约数据，尽管经过数据泛化，数据的具体情节被掩盖了，但泛化后的数据更有意义，更有利于人们去直观的理解。
 
 在具体问题的处理过程中，我们常常会遇到数值属性、分类属性等类别的属性需要通过数据泛化来将数据由繁至简。接下来，我们就分别对不同类别的属性的泛化进行简要的分析。
 
 \ding{172}对于数值属性，我们可以根据数据的分布自动的进行构造；例如，可以用分箱、聚类分析、基于熵的离散化等技术，可以将数值属性泛化。
 
 \ding{173}对于分类属性，有时可能具有很多个值。如果分类属性是序数属性，则可以使用类似于处理连续性属性的办法，以减少分类值的数目。如果分类属性是标称或者无序的，就需要使用其他办法。比如，就这次我们要解决的餐馆可接受的付款方式，因为，全球有多种被人们采用的消费方式，比如信用卡、现金、兑奖卷等等，而信用卡又分很多公司的或者银行的。因此，我们就要对付款方式进行泛化处理，比如，把类似于信用卡消费的归类与信用卡，将现金或者借记卡消费的归类于现金，将奖券等归类与其他方式消费等等。如果更深一层，我们可以根据餐馆可接受付款方式的多少将餐馆的消费方式设置成多样的和单一的两大类。
 
 此外，通过说明属性值的偏序或全序，可以很容易的定义概念分层。
 
 (4)规范化。数据规范化是将原来的度量值转换为无量纲的值，即将属性数据按比例缩放，使之落入一个小的特定区间。对于基于距离的方法，规范化可以帮助平衡具有较大初始值域的属性与较小初始值域的属性可比性。常用的规范化方法有以下几种：
 
 \begin{itemize}
 	\item 最小—最大规范化；
 		\item z-score规范化；
 			\item 小数定标规范化；
 \end{itemize}

(5)属性构造；

利用已知属性，可以构造新的属性，以更好地刻画数据的特性，帮助整个数据挖掘的过程。

在模型的构建的过程中，越是经过数据集经预处理之后留下关联度高和与最终要解决问题confidence高的属性，得到结果的正确性越高。我们知道，数据集的特征维数太高容易导致维灾难，而唯独太低又不能有效地捕获数据集中重要的信息。在实际应用中，通常需要对数据集中的特征进行处理来创建新的特征。有原始特征创建新的特征，其目的指在帮助特高挖掘结果正确度的精度以及对高维度数据结构的理解。

(6)数据离散化；

聚类、分类或关联分析中的某些算法要求数据是分类属性，因此需要对数值属性进行离散化。

\subsubsection{数据规约}

数据的不同视角反映出来的信息可能是不同的。

数据归约技术可以用来得到数据集的压缩表示，它比源数据集小得多，但仍然接近于保持原数据的完整性，这样在归约的数据集上挖掘将更有效，并能产生相同的分析结果。数据归约方法有以下几种：

(1)维度规约和特征变换

维度规约是指通过使用数据编码或变换，得到原始数据数据的规约或“压缩”表示。唯独规约有多方面的好处，最大的好处是，如果维度较低，许多数据挖掘算法的效果会更好。一方面是因为维规约可删除不相关的特征并降低噪声，另一方面是因为维灾难。在本文中，我们将要对用户信息数据进行聚类分析，如果原始数据集就对用户进行聚类划分，因为用户信息数据集的维度较高，所划分的簇中样本点之间的密度和距离之间的定义就变得没有多大意义了。此外，使用维规约，使模型涉及更少的特征，因而可以产生更容易理解的模型，可以降低数据挖掘算法的时间和空间复杂度。

接下来，简要介绍两种有效的有损规约方法：

\ding{172}离散小波变换(DWT)；

离散小波变换是一种线性信号处理技术，当用于数据向量I 时，将它转换成数值上不同的小波系数的向量，两个向量具有相同的长度。小波变换也可以用于多维数据，如数据立方体。

\ding{173}主成分分析；

设待压缩的数据由N个元组或数据向量组成，取k个维，主要成分分析搜索C个最能代表数据的K-1 维正交向量, 这样，原来的数据投影到一个较小的空间，导致数据压缩。不像属性子集选择通过保留原属性集的一个子集来减少属性集的大小，主要成分分析通过创建一个替换的、较小的变量集来组合属性的精华，原数据可以投影到该较小的集合中。与数据压缩的小波变换相比，主要成分分析能较好地处理稀疏数据，而小波变换更适合高维数据。

(2)抽样

选样作为一种数据归约技术，是用较小的随机样本子集表示大的数据集，选样种类：一是简单选择n个样本，不放回：由N个元组中抽取n个样本，其中任何元组被抽取的概率均为$\frac{1}{N}$。

二是简单选择n个样本，回放：一个元组被抽取后，它又被放回，以便可以再次抽取。

三是聚类选样：先将所有元组聚类，在从每个聚类中随机选取一个样本。

四是分层选样：将元组划分成不相交的部分，称作层，通过对每一层的简单随机选样得到总体样本的分层选样。

(3)数值压缩

数值归约技术可以通过选择替代的、“较小的”数据表示形式来减少数据量。这些技术可以是有参的，也可以是无参的。对于有参方法，使用一个模型来评估数据，是的只需要存放参数，而不是实际数据。无参方法包括直方图、聚类等等。

\ding{172}回归和对数线性模型。

回归和对数线性模型可以用来近似给定数据，在线性回归中，我们可以分局样本点的聚集程度建模，并使其走向适合一条直线，可以用以下公式将随机变量Y表示为另一随机变量X的线性函数，$Y=\alpha+\beta X$，系数$\alpha$和$\beta$称为回归系数，其值可以通过最小平方法求得，使得分离数据的实际直线与该直线的误差最小。对数线性模型近似离散的多维概率分布。基于较小的方体形成数据立方体的格，该方法可以用于估计具有离散属性集的基本方体中每个单元的概率。

其次，在对一个属性进行回归分析的时候，往往会涉及其他属性，尤其以线性回归作为处理方法。这时候涉及二维属性是否符合线性回归，就存在一个相关系数取值是否为1的问题，即
$|\rho(X,Y)|=1$。

相关系数$\rho(X,Y)$反映了属性之间的线性关系。以离散属性值为例，当$|\rho(X,Y)|=1$时，其属性之间几乎成线性关系，即属性之间的样本点几乎全部落在$Y=\alpha+\beta X$上。若$|\rho(X,Y)|=0$则属性之间无线性关联。现给出相关系数的求值公式：

\begin{equation}
\rho(X,Y)=\frac{\mathrm{cov(X,Y)}}{\sqrt{D(X)}\sqrt{D(Y)}}
\end{equation}

其中，$\mathrm{cov(X,Y)}$为属性X，Y之间的协方差，$D(X)$,$D(Y)$为属性X,Y的方差。其中$\mathrm{cov(X,Y)}=E(XY)-E(X)E(Y)$。

\ding{173}直方图。直方图使用分箱近似数据分布，是一种流行的数据归约形式，属性( 的直方图将( 的数据分布划分为不相交的子集或桶。桶安放在水平轴上，而桶的高度G和面积H是该桶所代表的值的平均频率。如每个桶只代表单个属性值K 频率对，则该桶称为单桶，通常桶表示给定属性的一个连续区间。

\ding{174}聚类。聚类技术将数据元组视为对象，将对象划分为群或聚类，使得在一个聚类中的对象“相似”。通常，类似性基于距离，用对象在空间中的接近程度定义，聚类的质量可以用直径表示，直径时一个聚类中两个任意对象的最大距离质心距离是聚类质量的另一种度量，是聚类质心到每个聚类对象的平均距离。在数据归约时，用数据的聚类表示替换实际数据。该技术的有效性依赖于数据的性质，如果数据能够组织成不同的聚类，该技术有效得多。

(4)特征选择

特征选择是指从一组已知特征集合中选择最具有代表性的特征子集，使其保留原有数据的大部分信息，即所选择的特征子集可以像原来的全部特征一样用来正确区分数据集中的每个数据对象。

